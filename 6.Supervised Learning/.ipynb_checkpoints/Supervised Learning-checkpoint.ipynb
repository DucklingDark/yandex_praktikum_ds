{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Общее-впечатление\" data-toc-modified-id=\"Общее-впечатление-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление</font></a></span></li></ul></li><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-данных-и-первичный-осмотр\" data-toc-modified-id=\"Загрузка-данных-и-первичный-осмотр-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Загрузка данных и первичный осмотр</a></span></li><li><span><a href=\"#Замена-имён-столбцов\" data-toc-modified-id=\"Замена-имён-столбцов-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Замена имён столбцов</a></span></li><li><span><a href=\"#Пропуски-в-данных\" data-toc-modified-id=\"Пропуски-в-данных-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Пропуски в данных</a></span></li><li><span><a href=\"#Дубликаты-данных\" data-toc-modified-id=\"Дубликаты-данных-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Дубликаты данных</a></span></li><li><span><a href=\"#Удаление-данных\" data-toc-modified-id=\"Удаление-данных-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Удаление данных</a></span></li><li><span><a href=\"#Преобразование-признаков\" data-toc-modified-id=\"Преобразование-признаков-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Преобразование признаков</a></span></li><li><span><a href=\"#Замена-типов-данных\" data-toc-modified-id=\"Замена-типов-данных-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Замена типов данных</a></span></li><li><span><a href=\"#Выбросы-и-аномалии\" data-toc-modified-id=\"Выбросы-и-аномалии-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Выбросы и аномалии</a></span></li><li><span><a href=\"#Распределение-целевого-признака\" data-toc-modified-id=\"Распределение-целевого-признака-1.9\"><span class=\"toc-item-num\">1.9&nbsp;&nbsp;</span>Распределение целевого признака</a></span></li><li><span><a href=\"#Выделение-целевого-признака\" data-toc-modified-id=\"Выделение-целевого-признака-1.10\"><span class=\"toc-item-num\">1.10&nbsp;&nbsp;</span>Выделение целевого признака</a></span></li><li><span><a href=\"#Разбиение-выборок\" data-toc-modified-id=\"Разбиение-выборок-1.11\"><span class=\"toc-item-num\">1.11&nbsp;&nbsp;</span>Разбиение выборок</a></span></li><li><span><a href=\"#Масштабирование-признаков\" data-toc-modified-id=\"Масштабирование-признаков-1.12\"><span class=\"toc-item-num\">1.12&nbsp;&nbsp;</span>Масштабирование признаков</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-1.13\"><span class=\"toc-item-num\">1.13&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Исследование-задачи\" data-toc-modified-id=\"Исследование-задачи-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Исследование задачи</a></span><ul class=\"toc-item\"><li><span><a href=\"#Дисбаланс-классов\" data-toc-modified-id=\"Дисбаланс-классов-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Дисбаланс классов</a></span></li><li><span><a href=\"#Обучение-моделей-на-несбалансированных-данных\" data-toc-modified-id=\"Обучение-моделей-на-несбалансированных-данных-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Обучение моделей на несбалансированных данных</a></span></li><li><span><a href=\"#Дерево-решений\" data-toc-modified-id=\"Дерево-решений-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Дерево решений</a></span></li><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Случайный лес</a></span></li><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Борьба-с-дисбалансом\" data-toc-modified-id=\"Борьба-с-дисбалансом-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Борьба с дисбалансом</a></span><ul class=\"toc-item\"><li><span><a href=\"#Взвешивание-классов\" data-toc-modified-id=\"Взвешивание-классов-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Взвешивание классов</a></span><ul class=\"toc-item\"><li><span><a href=\"#Дерево-решений\" data-toc-modified-id=\"Дерево-решений-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Дерево решений</a></span></li><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Случайный лес</a></span></li><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Итог\" data-toc-modified-id=\"Итог-3.1.4\"><span class=\"toc-item-num\">3.1.4&nbsp;&nbsp;</span>Итог</a></span></li></ul></li><li><span><a href=\"#Увеличение-выборки-(upsampling)\" data-toc-modified-id=\"Увеличение-выборки-(upsampling)-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Увеличение выборки (upsampling)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Дерево-решений\" data-toc-modified-id=\"Дерево-решений-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Дерево решений</a></span></li><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Случайный лес</a></span></li><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Итог\" data-toc-modified-id=\"Итог-3.2.4\"><span class=\"toc-item-num\">3.2.4&nbsp;&nbsp;</span>Итог</a></span></li></ul></li><li><span><a href=\"#Уменьшение-выборки-(downsampling)\" data-toc-modified-id=\"Уменьшение-выборки-(downsampling)-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Уменьшение выборки (downsampling)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Дерево-решений\" data-toc-modified-id=\"Дерево-решений-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Дерево решений</a></span></li><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-3.3.2\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span>Случайный лес</a></span></li><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-3.3.3\"><span class=\"toc-item-num\">3.3.3&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Итог\" data-toc-modified-id=\"Итог-3.3.4\"><span class=\"toc-item-num\">3.3.4&nbsp;&nbsp;</span>Итог</a></span></li></ul></li><li><span><a href=\"#Комбинируем-подходы\" data-toc-modified-id=\"Комбинируем-подходы-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Комбинируем подходы</a></span><ul class=\"toc-item\"><li><span><a href=\"#Дерево-решений\" data-toc-modified-id=\"Дерево-решений-3.4.1\"><span class=\"toc-item-num\">3.4.1&nbsp;&nbsp;</span>Дерево решений</a></span></li><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-3.4.2\"><span class=\"toc-item-num\">3.4.2&nbsp;&nbsp;</span>Случайный лес</a></span></li><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-3.4.3\"><span class=\"toc-item-num\">3.4.3&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Итог\" data-toc-modified-id=\"Итог-3.4.4\"><span class=\"toc-item-num\">3.4.4&nbsp;&nbsp;</span>Итог</a></span></li></ul></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Тестирование-модели\" data-toc-modified-id=\"Тестирование-модели-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Тестирование модели</a></span><ul class=\"toc-item\"><li><span><a href=\"#Взвешивание-классов-и-случайный-лес\" data-toc-modified-id=\"Взвешивание-классов-и-случайный-лес-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Взвешивание классов и случайный лес</a></span></li><li><span><a href=\"#Увеличение-выборки-и-случайный-лес\" data-toc-modified-id=\"Увеличение-выборки-и-случайный-лес-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Увеличение выборки и случайный лес</a></span></li><li><span><a href=\"#Уменьшение-выборки-и-случайный-лес\" data-toc-modified-id=\"Уменьшение-выборки-и-случайный-лес-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Уменьшение выборки и случайный лес</a></span></li><li><span><a href=\"#Увеличение-и-уменьшение-выборок-и-дерево-решений\" data-toc-modified-id=\"Увеличение-и-уменьшение-выборок-и-дерево-решений-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Увеличение и уменьшение выборок и дерево решений</a></span></li><li><span><a href=\"#Увеличение-и-уменьшение-выборок-и-случайный-лес\" data-toc-modified-id=\"Увеличение-и-уменьшение-выборок-и-случайный-лес-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Увеличение и уменьшение выборок и случайный лес</a></span></li><li><span><a href=\"#Проверка-моделей-на-адекватность\" data-toc-modified-id=\"Проверка-моделей-на-адекватность-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Проверка моделей на адекватность</a></span></li></ul></li><li><span><a href=\"#Общий-вывод\" data-toc-modified-id=\"Общий-вывод-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Общий вывод</a></span></li><li><span><a href=\"#Чек-лист-готовности-проекта\" data-toc-modified-id=\"Чек-лист-готовности-проекта-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Чек-лист готовности проекта</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отток клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\n",
    "\n",
    "Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. \n",
    "\n",
    "Постройте модель с предельно большим значением *F1*-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте *F1*-меру на тестовой выборке самостоятельно.\n",
    "\n",
    "Дополнительно измеряйте *AUC-ROC*, сравнивайте её значение с *F1*-мерой.\n",
    "\n",
    "Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание данных\n",
    "**Признаки**\n",
    "- RowNumber — индекс строки в данных\n",
    "- CustomerId — уникальный идентификатор клиента\n",
    "- Surname — фамилия\n",
    "- CreditScore — кредитный рейтинг\n",
    "- Geography — страна проживания\n",
    "- Gender — пол\n",
    "- Age — возраст\n",
    "- Tenure — сколько лет человек является клиентом банка\n",
    "- Balance — баланс на счёте\n",
    "- NumOfProducts — количество продуктов банка, используемых клиентом\n",
    "- HasCrCard — наличие кредитной карты\n",
    "- IsActiveMember — активность клиента\n",
    "- EstimatedSalary — предполагаемая зарплата\n",
    "\n",
    "**Целевой признак**\n",
    "- Exited — факт ухода клиента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подключим необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import time as tim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отключим предупреждения при вычислении F1 метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Отлично, что все импорты собраны в первой ячейке ноутбука! Если у того, кто будет запускать твой ноутбук будут отсутствовать некоторые библиотеки, то он это увидит сразу, а не в процессе!\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Без крайней необзодимости лучше не иоспользовать библиотеку plotly. Это сильно перегружает проект.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим переменную SEED для использования в качестве `random_state` параметра"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим функцию, которая выводит количество и процент пропусков данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nans_info(df):\n",
    "    nans_info = pd.DataFrame()\n",
    "    nans_info['count'] = df.isnull().sum()\n",
    "    nans_info['percent'] = (nans_info['count'] / df.shape[0] * 100).round(2)\n",
    "    nans_info = nans_info.sort_values(by='count', ascending=False)\n",
    "    display(nans_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных и первичный осмотр"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные и посмотрим на 25 случайных записей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/Churn.csv')\n",
    "df.sample(n=25, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим основную информацию о данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим основные статистики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Загрузка и первичный осмотр данных проведены хорошо.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Замена имён столбцов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменим имена столбцов, а именно:\n",
    "- приведём имена к нижнему регистру\n",
    "- разделим слова нижним подчёркиванием"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename({'rownumber': 'row_number', 'customerid': 'customer_id', \n",
    "                'creditscore': 'credit_score', 'numofproducts': 'num_of_products', \n",
    "                'hascrcard': 'has_cr_card', 'isactivemember': 'is_active_member', \n",
    "                'estimatedsalary': 'estimated_salary'},  axis='columns')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пропуски в данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_nans_info(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В столбце `tenure`, который хранит информацию о том, сколько лет человек является клиентом банка: \n",
    "- можно предположить, что эти данные пустые, так как человек только что стал клиентом и информация о нём ещё не готова полностью\n",
    "- с другой стороны, тогда было бы значение `0`\n",
    "\n",
    "Понять истинную причину не представляется возможным, как и найти закономерности для того, чтобы заполнить пропуски. В данном случае, любые варианты могут привести к искажению информации, что скажется на результатах<br>\n",
    "Пропусков достаточно много, 9%, но оставить их мы не можем, поэтому удалим их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "print_nans_info(df)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропуски удалены"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Удалить пропуски – достаточно безопасное решение.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дубликаты данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Количество дубликатов данных: ', df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дубликатов данных нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Удаление данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В датасете есть данные, которые не нужны для нашей работы: \n",
    "- номер строки данных\n",
    "- идентификатор клиента\n",
    "- фамилия клиента\n",
    "\n",
    "Удалим эти столбцы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.drop(['row_number', 'customer_id', 'surname'], axis=1)\n",
    "df.sample(n=10, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лишние столбцы удалены"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Согласен, чот эти колонки нам не нужны.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразование признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В таблице есть столбцы с географическим расположением и полом клиента<br>\n",
    "Посмотрим на уникальные значения столбца со страной клиента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['geography'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся методикой one-hot encoding и сделаем категориальные данные числовыми"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, drop_first=True)\n",
    "df.sample(n=10, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем имена столбцов к общему виду"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> В данном случае это наиболее подходящий способ закодировать пропуски.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename({'geography_Germany': 'geography_germany', 'geography_Spain': 'geography_spain', \n",
    "                'gender_Male': 'gender_male'},  axis='columns')\n",
    "df.sample(n=10, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Замена типов данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменим некоторые типы данных на более подходящее<br>\n",
    "Посмотрим ещё раз на значения столбцов и текущие типы данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данный момент, с учётом удалённых столбцов и данных, размер таблицы изменился с 2.6 Мб до 736.9 Кб<br>\n",
    "Заменим следующие типы у данных:\n",
    "- `age`, `tenure`, `num_of_products`, `has_cr_card`, `is_active_member`, `exited`, `geography_germany`, `geography_spain`, `gender_male` сменим на тип **uint8**\n",
    "- `credit_score` сменим на тип **uint16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uint8_columns = ['age', 'tenure', 'num_of_products', 'has_cr_card', 'is_active_member',\n",
    "                 'exited', 'geography_germany', 'geography_spain', 'gender_male']\n",
    "\n",
    "for column in uint8_columns:\n",
    "    df[column] = df[column].astype(np.uint8)\n",
    "    \n",
    "df['credit_score'] = df['credit_score'].astype(np.uint16)\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Типы данных заменены. Итоговый размер данных - 310.7 Кб. В сравнении с изначальным размером всех данных (2.6 Мб), экономия памяти составила 2352 Кб (2.3 Мб) или 758%. Удалось сократить размер таблицы данных в **7.5 раз**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбросы и аномалии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функции для построения графиков. Используем библиотеку plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_histogram(df, x, nbins, title, x_label, y_label, xticks):\n",
    "    fig = px.histogram(df, x=x, nbins=nbins, width=750, height=400)\n",
    "    fig.update_traces(marker_line_color='rgb(8,48,107)', marker_line_width=1.5, opacity=0.7)\n",
    "    fig.update_layout(title=title, xaxis_title=x_label, yaxis_title=y_label,\n",
    "                      xaxis = dict(tickmode = 'linear', dtick = xticks))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxplot(df, y, title, y_label):\n",
    "    fig = px.box(df, y=y, points='all', width=750, height=400)\n",
    "    fig.update_layout(title=title, yaxis_title=y_label)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределение данных по столбцу `credit_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_histogram(df, 'credit_score', nbins=50, title='Кредитный рейтинг', \n",
    "               x_label='Рейтинг', y_label='Количество записей', xticks=25)\n",
    "draw_boxplot(df, 'credit_score', title='Кредитный рейтинг', y_label='Рейтинг')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аномалий нет\n",
    "\n",
    "Теперь посмотрим на столбец `age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_histogram(df, 'age', nbins=50, title='Возраст клиентов', \n",
    "               x_label='Возраст', y_label='Количество записей', xticks=5)\n",
    "draw_boxplot(df, 'age', title='Возраст клиентов', y_label='Возраст')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть небольшое количество данных, которые можно считать выбросами - возраст больше 62х лет<br>\n",
    "Можно было бы избавиться от выбросов, так как, допустим, если единственный 92-летний клиент перестал пользоваться услугами банка, то предсказывая поведение клиентов схожего возраста, будет высока вероятность предсказания ухода<br>\n",
    "Но избавляться от этих данных нельзя, так как нам важно предсказать уход клиента, независимо от того, какой у него возраст\n",
    "\n",
    "Далее проверим столбец `tenure`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_histogram(df, 'tenure', nbins=30, title='Сколько лет клиент в банке', \n",
    "               x_label='Лет', y_label='Количество записей', xticks=1)\n",
    "draw_boxplot(df, 'tenure', title='Сколько лет клиент в банке', y_label='Лет')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аномалий нет\n",
    "\n",
    "Посмотрим на столбец `balance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_histogram(df, 'balance', nbins=60, title='Баланс на счёте', \n",
    "               x_label='Баланс', y_label='Количество записей', xticks=10000)\n",
    "draw_boxplot(df, 'balance', title='Баланс на счёте', y_label='Баланс')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут виден пик с очень большим количеством данных с нулевым балансом. От этих данных избавляться не будем. Возможно, у клиента есть продукт банка, но он им не пользуется. В таких случаях особенно важно понимать вероятность ухода клиента. Возможно, стоит предложить ему новые условия, чтобы привлечь его пользоваться продуктом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Распределение целевого признака"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на целевой признак - столбец `exited`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_histogram(df, 'exited', nbins=2, title='Факт ухода клиента', \n",
    "               x_label='Уход клиента', y_label='Количество записей', xticks=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим следующее: в данных по целевому признаку присутствует большой дисбаланс, данных об ещё не ушедших клиентах - 7237, а об ушедших - 1854, разница почти в 4 раза. Далее, мы попробуем обучить модели как на несбалансированных данных, так и после применения методов балансировки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Отлично, что был проведен исследовательский анализ признаков!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выделение целевого признака"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим из данных признаки для обучения моделей и целевой признак<br>\n",
    "Целевой признак - столбец `exited`, который хранит информацию о факте ухода клиента из банка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(['exited'], axis=1)\n",
    "target = df['exited']\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевой признак выделен"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбиение выборок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим функцию, которая выводит процент количества элементов одного датафрейма от другого"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elements_percent(title, first, second):\n",
    "    print(title, '{:.2%}'.format(first.shape[0]/second.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьём данные на обучающую, валидационную и тестовую выборки в соотношении 3:1:1, или 60%:20%:20%<br>\n",
    "Для этого, разделим сначала весь датасет на обучающую и тестовую выборки в соотношении 80%:20%. Затем, оставшиеся 80% обучающей выборки разделим на 60% обучающей и 20% валидационной, для чего укажем параметр `test_size=0.25`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=SEED\n",
    ")\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features_train, target_train, test_size=0.25, random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на количество элементов всех выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements_percent('Количество элементов обучающей выборки:', features_train, features)\n",
    "elements_percent('Количество элементов валидационной выборки:', features_valid, features)\n",
    "elements_percent('Количество элементов тестовой выборки:', features_test, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиение проведено верно: 60% исходных данных составляет обучающая выборка, а по 20% валидационная и тестовая выборки<br>\n",
    "Посмотрим на процент элементов одинакового класса в выборках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements_percent('Количество элементов одного класса обучающей выборки:', target_train[target_train == 1], target_train)\n",
    "elements_percent('Количество элементов одного класса валидационной выборки:', target_valid[target_valid == 1], target_valid)\n",
    "elements_percent('Количество элементов одного класса обучащей выборки:', target_test[target_test == 1], target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Процент элементов одного класса (`exited == 1`) во всех выборках примерно одинаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Разбиение было сделано правильно. Радует, что ты сам себя проверяешь!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Масштабирование признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Диапазоны значений у признаков очень разные. Применим подход масштабирования данных<br>\n",
    "Использовать будем структуру для масштабирования данных из библиотеке sklearn — StandardScaler<br>\n",
    "Посмотрим ещё раз на данные и информацию о них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train.sample(n=10, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем следующие столбцы: `credit_score`, `age`, `tenure`, `balance`, `num_of_products`, `estimated_salary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "pd.options.mode.chained_assignment = None\n",
    "numeric = ['credit_score', 'age', 'tenure', 'balance', 'num_of_products', 'estimated_salary']\n",
    "scaler.fit(features_train[numeric])\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Молодец, что обучил scaler только на тренировочной части данных. Это уменьшает переобучение.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train.sample(n=10, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы провели загрузку, первичный осмотр и подготовку данных:\n",
    "- названия столбцов приведены к единому формату\n",
    "- в данных были обнаружены пропуски в одном из столбцов (`tenure`). Данные с пропускаим были удалены, так как заполнить их достоверно нет возможности и попытки заполнить их приведут к искажению данных\n",
    "- дубликатов данных нет\n",
    "- данные, которые не нужны для исследования и построения моделей (номер клиента, его фамилия и номер строки в таблице) были удалены\n",
    "- категориальные признаки были приведены к числовым\n",
    "- типы данных заменены на более подходящие, размер данных стал меньше в 7.5 раз\n",
    "- выбросов и аномалий не было обнаружено\n",
    "- в данных большой дисбаланс по целевому признаку\n",
    "- выделили целевой признак\n",
    "- разбили данные на обучающую, валидационную и тестовую выборки\n",
    "- провели масштабирование данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследование задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дисбаланс классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомним, что в данных по целевому признаку был обнаружен сильный дисбаланс данных. Разница в количестве записей почти в 4 раза<br>\n",
    "На данном этапе не будем обращать внимания на дисбаланс. Проверим модели на тех данных, что у нас есть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение моделей на несбалансированных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модели на несбалансированных данных. Обучать будем три модели: \n",
    "- дерево решений\n",
    "- случайный лес\n",
    "- логистческая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функции, которые на вход принимают датафреймы для обучения и проверки модели, значения гиперпараметров, и возвращают значения `accuracy`, `f1` и `auc roc`<br>\n",
    "Перед ними, напишем функцию, которая принимает на вход модель, датафреймы, обучает модель, проверяет на выборке и возвращает `accuracy`, `f1` и `auc roc`<br>\n",
    "Посчитаем также, сколько будет работать каждая из моделей<br>\n",
    "Такое разбиение на функции сделает код более аккуратным и читаемым"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict(model, features_train, target_train, features_valid, target_valid):\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions = model.predict(features_valid)\n",
    "    probabilities = model.predict_proba(features_valid)\n",
    "    accuracy = accuracy_score(target_valid, predictions)\n",
    "    f1 = f1_score(target_valid, predictions)\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities[:,1])\n",
    "    return accuracy, f1, auc_roc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_fit_decision_tree(features_train, target_train, features_valid, target_valid, depth, class_weight):\n",
    "    start_time = tim.time()\n",
    "    model = DecisionTreeClassifier(random_state=SEED, max_depth=depth, class_weight=class_weight)\n",
    "    accuracy, f1, auc_roc = fit_and_predict(model, features_train, target_train, features_valid, target_valid)\n",
    "    work_time = tim.time() - start_time\n",
    "    return accuracy, f1, auc_roc, work_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_fit_random_forest(features_train, target_train, features_valid, target_valid, depth, estimators, class_weight):\n",
    "    start_time = tim.time()\n",
    "    model = RandomForestClassifier(random_state=SEED, n_estimators=estimators, max_depth=depth, class_weight=class_weight)\n",
    "    accuracy, f1, auc_roc = fit_and_predict(model, features_train, target_train, features_valid, target_valid)\n",
    "    work_time = tim.time() - start_time\n",
    "    return accuracy, f1, auc_roc, work_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_fit_logistic_regression(features_train, target_train, features_valid, target_valid, solver, class_weight):\n",
    "    start_time = tim.time()\n",
    "    model = LogisticRegression(random_state=SEED, solver=solver, class_weight=class_weight)\n",
    "    accuracy, f1, auc_roc = fit_and_predict(model, features_train, target_train, features_valid, target_valid)\n",
    "    work_time = tim.time() - start_time\n",
    "    return accuracy, f1, auc_roc, work_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получили набор функций для обучения и проверки различных моделей и эти функции **не зависят от конкретных датафреймов и настроек**, что может быть удобным для дальнейшего использования функций в других проектах\n",
    "\n",
    "\n",
    "Теперь напишем общую функцию, которая на вход принимает тип классификатора в виде строки, датафреймы, а также гиперпараметры<br> \n",
    "Гиперпараметры сделаем необязательными, так как не все параметры нужны для разных классификаторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_fit(model_type, features_train, target_train, features_valid, target_valid, \n",
    "                  max_depth=None, estimators=None, C=1.0, solver='warn', class_weight=None):\n",
    "    result = pd.DataFrame()\n",
    "    depth_array = []\n",
    "    estimators_array = []\n",
    "    accuracy_array = []\n",
    "    f1_array = []\n",
    "    auc_roc_array = []\n",
    "    time_array = []\n",
    "    \n",
    "    if model_type == 'Decision Tree':        \n",
    "        for depth in range(1, max_depth + 1):\n",
    "            accuracy, f1, auc_roc, work_time = train_and_fit_decision_tree(features_train, target_train,\n",
    "                                                                           features_valid, target_valid, \n",
    "                                                                           depth, class_weight)\n",
    "            depth_array.append(depth)\n",
    "            accuracy_array.append(accuracy)\n",
    "            f1_array.append(f1)\n",
    "            auc_roc_array.append(auc_roc)\n",
    "            time_array.append(work_time)\n",
    "        result['depth'] = depth_array\n",
    "            \n",
    "    elif model_type == 'Random Forest':\n",
    "        for depth in range(1, max_depth + 1):\n",
    "            for est in range(10, estimators + 1, 5):\n",
    "                accuracy, f1, auc_roc, work_time = train_and_fit_random_forest(features_train, target_train, \n",
    "                                                                               features_valid, target_valid, \n",
    "                                                                               depth, est, class_weight)\n",
    "                estimators_array.append(est)\n",
    "                depth_array.append(depth)\n",
    "                accuracy_array.append(accuracy)\n",
    "                f1_array.append(f1)\n",
    "                auc_roc_array.append(auc_roc)\n",
    "                time_array.append(work_time)\n",
    "        result['depth'] = depth_array\n",
    "        result['estimators'] = estimators_array\n",
    "        \n",
    "    elif model_type == 'Logistic Regression':\n",
    "        accuracy, f1, auc_roc, work_time = train_and_fit_logistic_regression(features_train, target_train, \n",
    "                                                                             features_valid, target_valid, \n",
    "                                                                             solver, class_weight)\n",
    "        accuracy_array.append(accuracy)\n",
    "        f1_array.append(f1)\n",
    "        auc_roc_array.append(auc_roc)\n",
    "        time_array.append(work_time)\n",
    "\n",
    "    result['accuracy'] = accuracy_array\n",
    "    result['f1'] = f1_array\n",
    "    result['auc_roc'] = auc_roc_array\n",
    "    result['time'] = time_array\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Такие сложные и длинные функции лучше не делать. Я бы сделал новую функцию для каждой модели.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим функцию отрисовки графика, которая на вход будет принимать массивы со значениями, по которым необходимо отрисовать линейные графики, массив значений для оси Y, а также строки с названиями для легенды и подписей осей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_line_plot(df, x, y_array, names_array='', \n",
    "                   title='', xlabel='', ylabel=''):\n",
    "    fig = go.Figure()\n",
    "    for i in range(0, len(y_array)):\n",
    "        fig.add_trace(go.Scatter(x=df[x], y=df[y_array[i]],\n",
    "                                 mode='lines', name=names_array[i]))\n",
    "        \n",
    "    fig.update_layout(title=title, xaxis_title=xlabel, yaxis_title=ylabel)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напием также функцию поиска максимумов каждой метрики. На вход функция примет датафрейм с результатами вычисления метрик модели, а на выход передаст максимальные значения и выводит строки датафрейма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_metrics(df):\n",
    "    accuracy = df['accuracy'].max()\n",
    "    display(df.query('accuracy == @accuracy'))\n",
    "    print('Наилучшее значение accuracy:', accuracy)\n",
    "    \n",
    "    f1 = df['f1'].max()\n",
    "    display(df.query('f1 == @f1'))\n",
    "    print('Наилучшее значение f1-меры:', f1)\n",
    "\n",
    "    auc_roc = df['auc_roc'].max()\n",
    "    display(df.query('auc_roc == @auc_roc'))\n",
    "    print('Наилучшее значение auc_roc:', auc_roc)\n",
    "    return accuracy, f1, auc_roc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также напишем функцию, которая соберёт лучшие метрики в одну таблицу<br>\n",
    "На вход передадим все максимальные значения метрик. Функция вернёт таблицу со всеми метриками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pivot_metrics(accuracy_metrics, f1_metrics, auc_roc_metrics):\n",
    "    data = {'accuracy': accuracy_metrics, 'f1': f1_metrics, 'auc-roc': auc_roc_metrics}\n",
    "    pivot = pd.DataFrame(data, columns=['accuracy', 'f1', 'auc-roc'], \n",
    "                         index=['Дерево решений', 'Случайный лес', 'Логистическая регрессия'])\n",
    "    return pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель дерева решений<br>\n",
    "Будем менять значение гиперпараметра `max_depth` от 1 до 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = train_and_fit('Decision Tree', features_train, target_train, \n",
    "                              features_valid, target_valid, max_depth=50)\n",
    "decision_tree.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "draw_line_plot(decision_tree, x='depth', y_array=['accuracy', 'f1', 'auc_roc'],\n",
    "               names_array=['ACCURACY', 'F1', 'AUC-ROC'], \n",
    "               title='Модель дерева решений', xlabel='Глубина дерева', ylabel='Значения метрик')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдём лучшие значения метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_maximum_accuracy, tree_maximum_f1, tree_maximum_auc_roc = get_top_metrics(decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшие значения метрик:\n",
    "- **accuracy** - 0.858 при максимальной глубине дерева 6\n",
    "- **f1** - 0.602 при максимальной глубине дерева 8, что удовлетворяет заданию, несмотря на сильно несбалансированные данные\n",
    "- **auc-roc** - 0.847 при максимальной глубине дерева 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь проверим модель случайного леса. Проверим как разную глубину дерева (от 1 до 10), так и число оценщиков (от 10 до 100 с шагом 5)<br>\n",
    "Найдём наилучшие результаты для каждой метрики и построим графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = train_and_fit('Random Forest', features_train, target_train, \n",
    "                              features_valid, target_valid, max_depth=10, estimators=100)\n",
    "            \n",
    "random_forest.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_maximum_accuracy, forest_maximum_f1, forest_maximum_auc_roc = get_top_metrics(random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим график наилучшей для метрики `accuracy` модели<br>\n",
    "Возьмём модель с глубиной 8, так как при этих значениях гиперпараметров наивысшая оценка F1 метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_depth_8 = random_forest.query('depth == 8')\n",
    "draw_line_plot(random_forest_depth_8, x='estimators', y_array=['accuracy', 'f1', 'auc_roc'],\n",
    "               names_array=['ACCURACY', 'F1', 'AUC-ROC'], \n",
    "               title='Модель случайного леса, лучшая для метрики Accuracy', \n",
    "               xlabel='Количество оценщиков', ylabel='Значения метрик')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для метрики `f1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_forest_depth_10 = random_forest.query('depth == 10')\n",
    "draw_line_plot(random_forest_depth_10, x='estimators', y_array=['accuracy', 'f1', 'auc_roc'],\n",
    "               names_array=['ACCURACY', 'F1', 'AUC-ROC'], \n",
    "               title='Модель случайного леса, лучшая для метрики F1', \n",
    "               xlabel='Количество оценщиков', ylabel='Значения метрик')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И для метрики `auc-roc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "random_forest_depth_9 = random_forest.query('depth == 9')\n",
    "draw_line_plot(random_forest_depth_9, x='estimators', y_array=['accuracy', 'f1', 'auc_roc'],\n",
    "               names_array=['ACCURACY', 'F1', 'AUC-ROC'], \n",
    "               title='Модель случайного леса, лучшая для метрики AUC-ROC', \n",
    "               xlabel='Количество оценщиков', ylabel='Значения метрик')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшие значения метрик:\n",
    "- **accuracy** - 0.866 при максимальной глубине дерева 7 и 8, и количестве оценщиков 45 и 50, но при одинаковом значении метрики, у второй пары гиперпараметров (8/50) выше значение метрики f1\n",
    "- **f1** - 0.589 при максимальной глубине дерева 10 и количестве оценщиков 80. Такое значение метрики не удовлетворяет заданию \n",
    "- **auc-roc** - 0.874 при максимальной глубине дерева 9 и количестве оценщиков 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на логистическую регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = train_and_fit('Logistic Regression', features_train, target_train, \n",
    "                                    features_valid, target_valid, solver='liblinear')\n",
    "logistic_maximum_accuracy, logistic_maximum_f1, logistic_maximum_auc_roc = get_top_metrics(logistic_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения метрик для логистической регрессии:\n",
    "- **accuracy** - 0.809\n",
    "- **f1** - 0.341\n",
    "- **auc-roc** - 0.794"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы обучили и протестировали на валидационной выборке модели, несмотря на то, что данные сильно несбалансированы и получили следующие результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_unbalanced = make_pivot_metrics([tree_maximum_accuracy, forest_maximum_accuracy, logistic_maximum_accuracy],\n",
    "                                        [tree_maximum_f1, forest_maximum_f1, logistic_maximum_f1], \n",
    "                                        [tree_maximum_auc_roc, forest_maximum_auc_roc, logistic_maximum_auc_roc])\n",
    "metrics_unbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшие показатели метрики **accuracy** показала модель **случайного леса** - 0.866<br>\n",
    "Наилучшие показатели метрики **f1** показала модель **дерева решений** - 0.602, что удовлетворяет трубованию задания<br>\n",
    "Наилучшие показатели метрики **auc-roc** показала модель **случайного леса** - 0.874<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Этот шаг был сделан отлично!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Борьба с дисбалансом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напомним, что соотношение данных по целевому признаку примерно 4:1\n",
    "Приступим к борьбе с дисбалансом в данных<br>\n",
    "Применим следующие методы борьбы с дисбалансом:\n",
    "- взвешивание классов\n",
    "- уменьшение количества объектов класса с большим количеством данных (downsampling)\n",
    "- увличение количества объектов класса с меньшим количеством данных (upsampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Взвешивание классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим ещё раз все модели, но на этот раз укажем параметр `class_weight='balanced'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = train_and_fit('Decision Tree', features_train, target_train, \n",
    "                              features_valid, target_valid, max_depth=50, class_weight='balanced')\n",
    "tree_maximum_accuracy, tree_maximum_f1, tree_maximum_auc_roc = get_top_metrics(decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = train_and_fit('Random Forest', features_train, target_train, \n",
    "                              features_valid, target_valid, max_depth=10, estimators=100, class_weight='balanced')\n",
    "forest_maximum_accuracy, forest_maximum_f1, forest_maximum_auc_roc = get_top_metrics(random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = train_and_fit('Logistic Regression', features_train, target_train, \n",
    "                                    features_valid, target_valid, solver='liblinear', class_weight='balanced')\n",
    "logistic_maximum_accuracy, logistic_maximum_f1, logistic_maximum_auc_roc = get_top_metrics(logistic_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Итог"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем первые результаты, полученные на несбалансированной выборке, а затем результаты, полученные после применения параметра `class_weight='balanced'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_class_weight = make_pivot_metrics([tree_maximum_accuracy, forest_maximum_accuracy, logistic_maximum_accuracy],\n",
    "                                          [tree_maximum_f1, forest_maximum_f1, logistic_maximum_f1], \n",
    "                                          [tree_maximum_auc_roc, forest_maximum_auc_roc, logistic_maximum_auc_roc])\n",
    "print('------- Несбалансрованные данные -------')\n",
    "display(metrics_unbalanced)\n",
    "print('--- Параметр class_weight=\"balanced\" ---')\n",
    "display(metrics_class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При использовании параметра `class_weight='balanced'` мы видим снижение значение значения метрики f1 у модели **дерева решений**. В тоже время, у **логистической регрессии** результат стал выше - **0.52**, а у **случайного леса** значение поднялось до **0.66**, что удовлетворяет требованию задания<br>\n",
    "Наилучшие значения метрик:\n",
    "- **accuracy** - 0.85 у модели случайного леса \n",
    "- **f1** - 0.66 у модели случайного леса\n",
    "- **auc-roc** - 0.87 у модели случайного леса\n",
    "\n",
    "В этот раз, модель случайного леса показала себя лучшей по всем метрикам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Я тоже обычно начинаю с перевзвешивания.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Увеличение выборки (upsampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Суть подхода состоит в том, чтобы увеличить количество объектов того класса, объектов которого меньше<br>\n",
    "Выполняется в следующие этапы:\n",
    "- разделяем выборку на объекты с положительным и отрицательным целевым признаком\n",
    "- копируем объекты с положительным целевым признаком (так как количество его объектов меньше)\n",
    "- создаём новую выборку с учётом увеличенного количества объектов с положительным целевым признаком\n",
    "- перемешиваем данные\n",
    "\n",
    "Напишем для этого функцию, которая на вход примет признаки, целевой признак и количество повторений (во сколько раз увеличить объём даных с положительным целевым признаком)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=SEED)\n",
    "    \n",
    "    return features_upsampled, target_upsampled "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь получим новые данные. Укажем параметр `repeat=4`, так как соотношение данныех примерно 4:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_upsampled, target_upsampled = upsample(features_train, target_train, repeat=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Верно, что параметр repeat был выбран равным 4-ем.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на график распределения целевого признака в данных, а также выведем процент количества объектов одного из классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_histogram(target_upsampled.to_frame(), 'exited', nbins=2, title='Факт ухода клиента', \n",
    "               x_label='Уход клиента', y_label='Количество записей', xticks=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements_percent('Количество элементов одного класса обучающей выборки:', \n",
    "                 target_upsampled[target_upsampled == 1], target_upsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что данные теперь сбалансированы по целевому признаку. Посмотрим ещё на общее количество элементов и можем переходить к проверкам моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_upsampled.shape)\n",
    "print(target_upsampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = train_and_fit('Decision Tree', features_upsampled, target_upsampled, \n",
    "                              features_valid, target_valid, max_depth=50)\n",
    "tree_maximum_accuracy, tree_maximum_f1, tree_maximum_auc_roc = get_top_metrics(decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = train_and_fit('Random Forest', features_upsampled, target_upsampled, \n",
    "                              features_valid, target_valid, max_depth=10, estimators=100)\n",
    "forest_maximum_accuracy, forest_maximum_f1, forest_maximum_auc_roc = get_top_metrics(random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = train_and_fit('Logistic Regression', features_upsampled, target_upsampled, \n",
    "                                    features_valid, target_valid, solver='liblinear')\n",
    "logistic_maximum_accuracy, logistic_maximum_f1, logistic_maximum_auc_roc = get_top_metrics(logistic_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Итог"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_upsampled = make_pivot_metrics([tree_maximum_accuracy, forest_maximum_accuracy, logistic_maximum_accuracy],\n",
    "                                       [tree_maximum_f1, forest_maximum_f1, logistic_maximum_f1], \n",
    "                                       [tree_maximum_auc_roc, forest_maximum_auc_roc, logistic_maximum_auc_roc])\n",
    "print('--------- Несбалансрованные данные ---------')\n",
    "display(metrics_unbalanced)\n",
    "print('----- Параметр class_weight=\"balanced\" -----')\n",
    "display(metrics_class_weight)\n",
    "print('--- Сбалансированные данные (upsampled) ---')\n",
    "display(metrics_upsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При использовании подхода `upsampling`, по сравнению с параметром `class_weight='balanced'`, значения большинства метрик немного упали. Лучше всех (для метрики **f1**) снова оказалась модель **случайного леса**, показав значение метрики **0.65**, что удовлетворяет заданию<br>\n",
    "Наилучшие значения метрик:\n",
    "- **accuracy** - 0.83 у модели случайного леса \n",
    "- **f1** - 0.65 у модели случайного леса\n",
    "- **auc-roc** - 0.876 у модели логистической регрессии\n",
    "\n",
    "В этот раз, модель случайного леса показала себя лучшей по всем метрикам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Уменьшение выборки (downsampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Суть подхода состоит в том, чтобы уменьшить количество объектов того класса, объектов которого больше<br>\n",
    "Выполняется в следующие этапы:\n",
    "- разделяем выборку на объекты с положительным и отрицательным целевым признаком\n",
    "- случайно отбрасываем часть объектов с отрицательным целевым признаком\n",
    "- создаём новую выборку, с учётом уменьшенного количества объектов с отрицательным целевым признаком\n",
    "- перемешиваем данные\n",
    "\n",
    "Напишем для этого функцию, которая на вход примет признаки, целевой признак и долю объектов с отрицательным целевым признаком "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat([features_zeros.sample(frac=fraction, random_state=SEED)] + [features_ones])\n",
    "    target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state=SEED)] + [target_ones])\n",
    "    features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled, random_state=SEED)\n",
    "    \n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим функцию, передав параметр `fraction=0.25`, тем самым оставив четверть данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_downsampled, target_downsampled = downsample(features_train, target_train, fraction=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на график распределения целевого признака в данных, а также выведем процент количества объектов одного из классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_histogram(target_downsampled.to_frame(), 'exited', nbins=2, title='Факт ухода клиента', \n",
    "               x_label='Уход клиента', y_label='Количество записей', xticks=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements_percent('Количество элементов одного класса обучающей выборки:', \n",
    "                 target_downsampled[target_downsampled == 1], target_downsampled)\n",
    "print(features_downsampled.shape)\n",
    "print(target_downsampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = train_and_fit('Decision Tree', features_downsampled, target_downsampled, \n",
    "                              features_valid, target_valid, max_depth=50)\n",
    "tree_maximum_accuracy, tree_maximum_f1, tree_maximum_auc_roc = get_top_metrics(decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = train_and_fit('Random Forest', features_downsampled, target_downsampled, \n",
    "                              features_valid, target_valid, max_depth=10, estimators=100)\n",
    "forest_maximum_accuracy, forest_maximum_f1, forest_maximum_auc_roc = get_top_metrics(random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = train_and_fit('Logistic Regression', features_downsampled, target_downsampled, \n",
    "                                    features_valid, target_valid, solver='liblinear')\n",
    "logistic_maximum_accuracy, logistic_maximum_f1, logistic_maximum_auc_roc = get_top_metrics(logistic_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Итог"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_downsampled = make_pivot_metrics([tree_maximum_accuracy, forest_maximum_accuracy, logistic_maximum_accuracy],\n",
    "                                         [tree_maximum_f1, forest_maximum_f1, logistic_maximum_f1], \n",
    "                                         [tree_maximum_auc_roc, forest_maximum_auc_roc, logistic_maximum_auc_roc])\n",
    "print('---------- Несбалансрованные данные ----------')\n",
    "display(metrics_unbalanced)\n",
    "print('------ Параметр class_weight=\"balanced\" ------')\n",
    "display(metrics_class_weight)\n",
    "print('---- Сбалансированные данные (upsampled) ----')\n",
    "display(metrics_upsampled)\n",
    "print('--- Сбалансированные данные (downsampled) ---')\n",
    "display(metrics_downsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При использовании подхода `downsampling`, по сравнению с методом `upsampling`, значения части метрик упали, а часть увеличилась. Лучше всех (для метрики **f1**) снова оказалась модель **случайного леса**, показав значение метрики **0.628**, что удовлетворяет заданию<br>\n",
    "Наилучшие значения метрик:\n",
    "- **accuracy** - 0.80 у модели случайного леса \n",
    "- **f1** - 0.628 у модели случайного леса\n",
    "- **auc-roc** - 0.87 у модели случайного леса\n",
    "\n",
    "В этот раз, модель случайного леса также показала себя лучшей по всем метрикам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Комбинируем подходы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем скомбинировать предыдущие два подхода:\n",
    "- увеличим в 2 раза количество объектов положительного класса\n",
    "- оставим половину объектов отрицательного класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_up, target_up = upsample(features_train, target_train, repeat=2)\n",
    "features_up_down, target_up_down = downsample(features_up, target_up, fraction=0.5)\n",
    "draw_histogram(target_up_down.to_frame(), 'exited', nbins=2, title='Факт ухода клиента', \n",
    "               x_label='Уход клиента', y_label='Количество записей', xticks=1)\n",
    "elements_percent('Количество элементов одного класса обучающей выборки:', \n",
    "                 target_up_down[target_up_down == 1], target_up_down)\n",
    "print(features_up_down.shape)\n",
    "print(target_up_down.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Хорошая идея!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = train_and_fit('Decision Tree', features_up_down, target_up_down, \n",
    "                              features_valid, target_valid, max_depth=50)\n",
    "tree_maximum_accuracy, tree_maximum_f1, tree_maximum_auc_roc = get_top_metrics(decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = train_and_fit('Random Forest', features_up_down, target_up_down, \n",
    "                              features_valid, target_valid, max_depth=10, estimators=100)\n",
    "forest_maximum_accuracy, forest_maximum_f1, forest_maximum_auc_roc = get_top_metrics(random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = train_and_fit('Logistic Regression', features_up_down, target_up_down, \n",
    "                                    features_valid, target_valid, solver='liblinear')\n",
    "logistic_maximum_accuracy, logistic_maximum_f1, logistic_maximum_auc_roc = get_top_metrics(logistic_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Итог"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_up_down = make_pivot_metrics([tree_maximum_accuracy, forest_maximum_accuracy, logistic_maximum_accuracy],\n",
    "                                         [tree_maximum_f1, forest_maximum_f1, logistic_maximum_f1], \n",
    "                                         [tree_maximum_auc_roc, forest_maximum_auc_roc, logistic_maximum_auc_roc])\n",
    "print('---------- Несбалансрованные данные ----------')\n",
    "display(metrics_unbalanced)\n",
    "print('------ Параметр class_weight=\"balanced\" ------')\n",
    "display(metrics_class_weight)\n",
    "print('---- Сбалансированные данные (upsampled) ----')\n",
    "display(metrics_upsampled)\n",
    "print('--- Сбалансированные данные (downsampled) ---')\n",
    "display(metrics_downsampled)\n",
    "print('--- Сбалансированные данные (up/downsampl) ---')\n",
    "display(metrics_up_down)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы скомбинировали методы увеличения и уменьшения частей выборок<br>\n",
    "По сравнению с другими методами, модель **дерево решеинй** показала наилучший (для себя) результат для метрики **f1** (среди других методов борьбы с дисбалансом) - **0.61**, что удовлетворяет заданию<br>\n",
    "Лучше всех (для метрики **f1**) снова оказалась модель **случайного леса**, показав значение метрики **0.632**, что также удовлетворяет заданию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы применили несколько различных сособов борьбы с дисбалансом в данных, обучили на них модели и проверили, как это влияет на результаты<br>\n",
    "Удовлетворяющие результаты для метрики **f1** дали следующие модели при следующих подходах к балансировке данных:\n",
    "- взвешивание классов:\n",
    "    - модель случайного леса\n",
    "    - f1 = 0.66\n",
    "    - глубина дерева 10\n",
    "    - количество оценщиков 65\n",
    "    - время работы 0.466 с\n",
    "- увеличение выборки:\n",
    "    - модель случайного леса\n",
    "    - f1 = 0.65\n",
    "    - глубина дерева 9 \n",
    "    - количество оценщиков 100\n",
    "    - время работы 1.37 с\n",
    "- уменьшение выборки:\n",
    "    - модель случайного леса\n",
    "    - f1 = 0.628\n",
    "    - глубина дерева 7\n",
    "    - количество оценщиков 85\n",
    "    - время работы 0.322 с\n",
    "- уменьшение и увеличение выборок:\n",
    "    - модель дерева решений\n",
    "    - f1 = 0.611\n",
    "    - глубина дерева 7\n",
    "    - время работы 0.025 с\n",
    "- уменьшение и увеличение выборок:    \n",
    "    - модель случайного леса\n",
    "    - f1 = 0.632\n",
    "    - глубина дерева 10\n",
    "    - количество оценщиков 75\n",
    "    - время работы 0.483 с"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Этот шаг был сделан восхитительно!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем наилучшие модели при оптимальных гиперпараметрах и методах борьбы с дисбалансмо на тестовой выборке и вычислим значения метрики **F1** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Взвешивание классов и случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель случайного дерева при следующих условиях:\n",
    "- данные несбалансированы\n",
    "- максимальная глубина дерева 10\n",
    "- количество оценщиков 65\n",
    "- указан параметр `class_weight=balanced`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=SEED, n_estimators=65, max_depth=10, class_weight='balanced')\n",
    "accuracy, f1, auc_roc = fit_and_predict(model, features_train, target_train, features_test, target_test)\n",
    "print('accuracy =', accuracy)\n",
    "print('f1 =', f1)\n",
    "print('auc-roc =', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 метрика выше требуемого значения 0.59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Увеличение выборки и случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель случайного дерева при следующих условиях:\n",
    "- данные сбалансированы методом upsampling\n",
    "- максимальная глубина дерева 9\n",
    "- количество оценщиков 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=SEED, n_estimators=100, max_depth=9)\n",
    "accuracy, f1, auc_roc = fit_and_predict(model, features_upsampled, target_upsampled, features_test, target_test)\n",
    "print('accuracy =', accuracy)\n",
    "print('f1 =', f1)\n",
    "print('auc-roc =', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 метрика также выше требуемого значения 0.59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Уменьшение выборки и случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель случайного дерева при следующих условиях:\n",
    "- данные сбалансированы методом downsampling\n",
    "- максимальная глубина дерева 7\n",
    "- количество оценщиков 85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=SEED, n_estimators=85, max_depth=7)\n",
    "accuracy, f1, auc_roc = fit_and_predict(model, features_downsampled, target_downsampled, features_test, target_test)\n",
    "print('accuracy =', accuracy)\n",
    "print('f1 =', f1)\n",
    "print('auc-roc =', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение метрики F1 ниже требуемого значения 0.59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Увеличение и уменьшение выборок и дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель дерева решений при следующих условиях:\n",
    "- данные сбалансированы методом downsampling и upsamling\n",
    "- максимальная глубина дерева 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=SEED, max_depth=7)\n",
    "accuracy, f1, auc_roc = fit_and_predict(model, features_up_down, target_up_down, features_test, target_test)\n",
    "print('accuracy =', accuracy)\n",
    "print('f1 =', f1)\n",
    "print('auc-roc =', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение метрики F1 меньше требуемого значения 0.59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Увеличение и уменьшение выборок и случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель случайного леса при следующих условиях:\n",
    "- данные сбалансированы методом downsampling и upsamling\n",
    "- максимальная глубина дерева 10\n",
    "- число оценщиков 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=SEED, n_estimators=75, max_depth=10)\n",
    "accuracy, f1, auc_roc = fit_and_predict(model, features_up_down, target_up_down, features_test, target_test)\n",
    "print('accuracy =', accuracy)\n",
    "print('f1 =', f1)\n",
    "print('auc-roc =', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение метрики F1 выше требуемого значения 0.59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Тестирваоние сделано праивльно. Требуемое качество достигнуто.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка моделей на адекватность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним наши лучшие модели с так называемым `Dummy` классификатором. В случае, если точность наших моделей будет выше, значит их предсказания точнее случайного угадывания<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fit_predict_dummy(features_train, target_train, features_test, target_test, strategy):\n",
    "    model = DummyClassifier(random_state=SEED, strategy=strategy)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions = model.predict(features_valid)\n",
    "    probabilities = model.predict_proba(features_valid)\n",
    "    accuracy = accuracy_score(target_valid, predictions)\n",
    "    f1 = f1_score(target_valid, predictions)\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities[:,1])\n",
    "    return accuracy, f1, auc_roc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим теперь метрики Dummy классификатора со следующими возможными значениями гиперпараметра `strategy`:\n",
    "- stratified\n",
    "- most_frequent\n",
    "- prior\n",
    "- uniform\n",
    "\n",
    "Также, будем проверять на обучающей выборке при всех вариантах балансировки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = ['stratified', 'most_frequent', 'prior', 'uniform']\n",
    "for strategy in strategies:    \n",
    "    accuracy, f1, auc_roc = train_fit_predict_dummy(features_upsampled, target_upsampled, \n",
    "                                                    features_test, target_test, strategy=strategy)\n",
    "    print('------------------------------')\n",
    "    print('Accuracy Dummy со стратегией', strategy, 'на тестовой выборке при upsamling:', accuracy)\n",
    "    print('F1 Dummy со стратегией', strategy, 'на тестовой выборке при upsamling:', f1)\n",
    "    print('AUC-ROC Dummy со стратегией', strategy, 'на тестовой выборке при upsamling:', auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = ['stratified', 'most_frequent', 'prior', 'uniform']\n",
    "for strategy in strategies:    \n",
    "    accuracy, f1, auc_roc = train_fit_predict_dummy(features_downsampled, target_downsampled, \n",
    "                                                    features_test, target_test, strategy=strategy)\n",
    "    print('------------------------------')\n",
    "    print('Accuracy Dummy со стратегией', strategy, 'на тестовой выборке при downsamling:', accuracy)\n",
    "    print('F1 Dummy со стратегией', strategy, 'на тестовой выборке при downsamling:', f1)\n",
    "    print('AUC-ROC Dummy со стратегией', strategy, 'на тестовой выборке при downsamling:', auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = ['stratified', 'most_frequent', 'prior', 'uniform']\n",
    "for strategy in strategies:    \n",
    "    accuracy, f1, auc_roc = train_fit_predict_dummy(features_up_down, target_up_down, \n",
    "                                                    features_test, target_test, strategy=strategy)\n",
    "    print('------------------------------')\n",
    "    print('Accuracy Dummy со стратегией', strategy, 'на тестовой выборке при up_downsamling:', accuracy)\n",
    "    print('F1 Dummy со стратегией', strategy, 'на тестовой выборке при up_downsamling:', f1)\n",
    "    print('AUC-ROC Dummyсо стратегией', strategy, 'на тестовой выборке при up_downsamling:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все метрики Dummy классификатора ниже при любой стратегии и любом подходе к балансировке данных, что говорит нам о том, что наши модели проходят проверку на адекватность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Был проведён осмотр данных и их предобработка:\n",
    "- из данных удалены ненужные для исследования столбцы\n",
    "- преобразованы категориальные признаки в численные методом One Hot Encoding\n",
    "- заменены типы данных, что дало возможность уменьшить объём исследуемых данных в 7.5 раз\n",
    "- значения данных были масштабированы\n",
    "- в данных был обнаружен дисбаланс по целевому признаку 4:1 \n",
    "\n",
    "Был проведён анализ данных без учёта дисбаланса данных по целевому признаку на валиационной выборке:\n",
    "- максимальное значение accuracy было достигнуто на модели **случайного леса** - 0.866\n",
    "- максимальное значение f1 было достигнуто на модели **дерева решений** - 0.602, что выше требуемого значения в 0.59 \n",
    "- максимальное значение auc-roc было достигнуто на модели **случайного леса** - 0.874\n",
    "\n",
    "Далее были обучены и проверены модели при разном подходе к балансировке данных на валидационной выборке<br>\n",
    "Удовлетворяющие результаты для метрики **f1** дали следующие модели при следующих подходах к балансировке данных:\n",
    "- взвешивание классов и модель случайного леса: f1 = 0.66, auc-roc = 0.875\n",
    "- увеличение выборки и модель случайного леса: f1 = 0.65, auc-roc = 0.876\n",
    "- уменьшение выборки и модель случайного леса: f1 = 0.628, auc-roc = 0.873\n",
    "- уменьшение и увеличение выборок, модель дерева решений: f1 = 0.611, auc-roc = 0.849\n",
    "- уменьшение и увеличение выборок, модель случайного леса: f1 = 0.632, auc-roc = 0.876\n",
    "\n",
    "Далее были обучены и проверены оптимальные модели при оптимальных методах балансировки данных на тестовой выборке<br>\n",
    "Удовлетворяющие результаты для метрики **f1**:\n",
    "- взвешивание классов и модель случайного леса: f1 = 0.592, auc-roc = 0.851\n",
    "- увеличение выборки и модель случайного леса: f1 = 0.596, auc-roc = 0.857\n",
    "- уменьшение и увеличение выборок, модель случайного леса: f1 = 0.598, auc-roc = 0.852"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "614.4px",
    "left": "141px",
    "top": "110.8px",
    "width": "289.25px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
